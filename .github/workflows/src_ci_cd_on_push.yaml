name: Source code Push CI/CD Workflow

on:
    push:
        paths:
            - "src/**"
        branches:
            - main

    workflow_dispatch:

env:
    AWS_REGION: ${{ vars.AWS_DEFAULT_REGION }}

jobs:
    src_test:
        uses: ./.github/workflows/src_ci_on_pull_request.yaml

    check_staging_infrastructure_exists:
        runs-on: ubuntu-latest
        environment:
            name: staging

        env:
            AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
            AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

        outputs:
            instance_exists: ${{ steps.instance_exists.outputs.instance_exists }}

        steps:
            - name: Check if staging environment is up
              id: get_instance_id
              run: |
                  INSTANCE_ID=$(aws ec2 describe-instances \
                                    --filters "Name=tag:Name,Values=github-actions-staging-instance" \
                                    --query "Reservations[*].Instances[*].InstanceId" \
                                    --region ${{ vars.AWS_DEFAULT_REGION }} \
                                    --output text)

                    echo "instance_id=$INSTANCE_ID" >> $GITHUB_OUTPUT

            - name: Output if it exists or not
              id: instance_exists
              run: |
                  if [[ -z "${{ steps.get_instance_id.outputs.instance_id }}" || "${{ steps.get_instance_id.outputs.instance_id }}" == 'None' ]]; then
                      echo "instance_exists=false" >> $GITHUB_OUTPUT
                  else
                      echo "instance_exists=true" >> $GITHUB_OUTPUT
                  fi

    deploy_staging_infrastructure:
        needs: check_staging_infrastructure_exists
        if: needs.check_staging_infrastructure_exists.outputs.instance_exists == 'false'
        uses: ./.github/workflows/staging_infra_deployment.yaml
        secrets:
            AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
            AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
            TF_API_TOKEN: ${{ secrets.TF_API_TOKEN }}

    src_deploy_to_staging:
        runs-on: ubuntu-latest
        needs:
            - src_test
            - deploy_staging_infrastructure

        if: always() && needs.src_test.result == 'success' && (needs.deploy_staging_infrastructure.result == 'success' || needs.deploy_staging_infrastructure.result == 'skipped')

        environment:
            name: staging

        env:
            AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
            AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

        steps:
            - name: Checkout repository
              uses: actions/checkout@v5

            - name: Get the instance id of the staging instance
              id: get_instance_id
              run: |
                  INSTANCE_ID=$(aws ec2 describe-instances \
                                  --filters "Name=tag:Name,Values=github-actions-staging-instance" \
                                  --query "Reservations[*].Instances[*].InstanceId" \
                                  --region ${{ vars.AWS_DEFAULT_REGION }} \
                                  --output text)

                  echo "instance_id=$INSTANCE_ID" >> $GITHUB_OUTPUT

            - name: Check if the staging instance exists
              if: steps.get_instance_id.outputs.instance_id == '' || steps.get_instance_id.outputs.instance_id == 'None'
              run: |
                  echo "Staging instance does not exist. Exiting..."
                  exit 1

            - name: Get staging instance public ip
              id: get_staging_instance_public_ip
              run: |
                  PUBLIC_IP=$(aws ec2 describe-instances \
                                --instance-ids ${{ steps.get_instance_id.outputs.instance_id }} \
                                --query 'Reservations[0].Instances[0].PublicIpAddress' \
                                --region ${{ vars.AWS_DEFAULT_REGION }} \
                                --output text)

                  echo "instance_public_ip=$PUBLIC_IP" >> $GITHUB_OUTPUT

            - name: Get staging instance security group
              id: get_staging_instance_security_group
              run: |
                  SG_ID=$(aws ec2 describe-instances \
                              --instance-ids ${{ steps.get_instance_id.outputs.instance_id }} \
                              --query "Reservations[*].Instances[*].SecurityGroups[*].GroupId" \
                              --region ${{ vars.AWS_DEFAULT_REGION }} \
                              --output text)

                  echo "security_group_id=$SG_ID" >> $GITHUB_OUTPUT

            - name: Get runner public ip
              id: get_runner_public_ip
              run: |
                  PUBLIC_IP=$(curl -s https://api.ipify.org)
                  echo "runner_public_ip=$PUBLIC_IP" >> $GITHUB_OUTPUT

            - name: Allow ssh on the security group of instance from the runner ip
              run: |
                  aws ec2 authorize-security-group-ingress \
                      --group-id ${{ steps.get_staging_instance_security_group.outputs.security_group_id }} \
                      --ip-permissions \
                      "IpProtocol=tcp,FromPort=22,ToPort=22,IpRanges=[{CidrIp=${{ steps.get_runner_public_ip.outputs.runner_public_ip }}/32,Description='Allow ssh from runner'}]"
                      --region ${{ vars.AWS_DEFAULT_REGION }}

            - name: Deploy to staging instance
              uses: burnett01/rsync-deployments@7.1.0
              with:
                  switches: -azvr --delete
                  path: src/
                  remote_path: /opt/app/
                  remote_host: ${{ steps.get_staging_instance_public_ip.outputs.instance_public_ip }}
                  remote_user: ${{ secrets.EC2_USER }}
                  remote_key: ${{ secrets.EC2_PRIVATE_KEY }}

            - name: Start or Restart the node server with pm2
              uses: appleboy/ssh-action@v1
              with:
                  host: ${{ steps.get_staging_instance_public_ip.outputs.instance_public_ip }}
                  username: ${{ secrets.EC2_USER }}
                  key: ${{ secrets.EC2_PRIVATE_KEY }}
                  script: |
                      cd /opt/app
                      npm ci --only=production
                      pm2 reload "node-server" --update-env || pm2 start /opt/app/bin/www --name "node-server" --update-env
                      sudo systemctl reload nginx

            - name: Disallow ssh on the security group of instance from the runner ip
              run: |
                  aws ec2 revoke-security-group-ingress \
                      --group-id ${{ steps.get_staging_instance_security_group.outputs.security_group_id }} \
                      --protocol tcp \
                      --port 22 \
                      --cidr "${{ steps.get_runner_public_ip.outputs.runner_public_ip }}/32"
                      --region ${{ vars.AWS_DEFAULT_REGION }}

    check_production_infrastructure_exists:
        runs-on: ubuntu-latest
        environment:
            name: production

        env:
            AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
            AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

        outputs:
            instance_exists: ${{ steps.instance_exists.outputs.instance_exists }}

        steps:
            - name: Check if production environment is up
              id: get_instance_id
              run: |
                  INSTANCE_ID=$(aws ec2 describe-instances \
                                    --filters "Name=tag:Name,Values=github-actions-prod-instance" \
                                    --query "Reservations[*].Instances[*].InstanceId" \
                                    --region ${{ vars.AWS_DEFAULT_REGION }} \
                                    --output text)

                    echo "instance_id=$INSTANCE_ID" >> $GITHUB_OUTPUT

            - name: Output if it exists or not
              id: instance_exists
              run: |
                  if [[ -z "${{ steps.get_instance_id.outputs.instance_id }}" || "${{ steps.get_instance_id.outputs.instance_id }}" == 'None' ]]; then
                      echo "instance_exists=false" >> $GITHUB_OUTPUT
                  else
                      echo "instance_exists=true" >> $GITHUB_OUTPUT
                  fi

    deploy_production_infrastructure:
        needs: check_production_infrastructure_exists
        if: needs.check_production_infrastructure_exists.outputs.instance_exists == 'false'
        uses: ./.github/workflows/prod_infra_deployment.yaml
        secrets:
            AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
            AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
            TF_API_TOKEN: ${{ secrets.TF_API_TOKEN }}

    src_deploy_to_production:
        runs-on: ubuntu-latest
        needs:
            - src_deploy_to_staging
            - deploy_production_infrastructure

        if: always() && needs.src_deploy_to_staging.result == 'success' && (needs.deploy_production_infrastructure.result == 'success' || needs.deploy_production_infrastructure.result == 'skipped')

        environment:
            name: production

        env:
            AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
            AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

        steps:
            - name: Checkout repository
              uses: actions/checkout@v5

            - name: Get the instance id of the production instance
              id: get_instance_id
              run: |
                  INSTANCE_ID=$(aws ec2 describe-instances \
                                  --filters "Name=tag:Name,Values=github-actions-prod-instance" \      
                                  --query "Reservations[*].Instances[*].InstanceId" \
                                  --region ${{ vars.AWS_DEFAULT_REGION }} \
                                  --output text)

                  echo "instance_id=$INSTANCE_ID" >> $GITHUB_OUTPUT

            - name: Check if the production instance exists
              if: steps.get_instance_id.outputs.instance_id == '' || steps.get_instance_id.outputs.instance_id == 'None'
              run: |
                  echo "Production instance does not exist. Exiting..."
                  exit 1

            - name: Get production instance public ip
              id: get_instance_public_ip
              run: |
                  PUBLIC_IP=$(aws ec2 describe-instances \
                                --instance-ids ${{ steps.get_instance_id.outputs.instance_id }} \
                                --query 'Reservations[0].Instances[0].PublicIpAddress' \
                                --region ${{ vars.AWS_DEFAULT_REGION }} \
                                --output text)

                  echo "instance_public_ip=$PUBLIC_IP" >> $GITHUB_OUTPUT

            - name: Get production instance security group
              id: get_instance_security_group
              run: |
                  SG_ID=$(aws ec2 describe-instances \
                              --instance-ids ${{ steps.get_instance_id.outputs.instance_id }} \          
                              --query "Reservations[*].Instances[*].SecurityGroups[*].GroupId" \
                              --region ${{ vars.AWS_DEFAULT_REGION }} \
                              --output text)

                  echo "security_group_id=$SG_ID" >> $GITHUB_OUTPUT

            - name: Get runner public ip
              id: get_runner_public_ip
              run: |
                  PUBLIC_IP=$(curl -s https://api.ipify.org)
                  echo "runner_public_ip=$PUBLIC_IP" >> $GITHUB_OUTPUT

            - name: Allow ssh on the security group of instance from the runner ip
              run: |
                  aws ec2 authorize-security-group-ingress \
                      --group-id ${{ steps.get_instance_security_group.outputs.security_group_id }} \
                      --ip-permissions \
                      "IpProtocol=tcp,FromPort=22,ToPort=22,IpRanges=[{CidrIp=${{ steps.get_runner_public_ip.outputs.runner_public_ip }}/32,Description='Allow ssh from runner'}]"
                      --region ${{ vars.AWS_DEFAULT_REGION }}

            - name: Deploy to production instance
              uses: burnett01/rsync-deployments@7.1.0
              with:
                  switches: -azvr --delete
                  path: src/
                  remote_path: /opt/app/
                  remote_host: ${{ steps.get_instance_public_ip.outputs.instance_public_ip }}
                  remote_user: ${{ secrets.EC2_USER }}
                  remote_key: ${{ secrets.EC2_PRIVATE_KEY }}

            - name: Start or Restart the node server with pm2
              uses: appleboy/ssh-action@v1
              with:
                  host: ${{ steps.get_instance_public_ip.outputs.instance_public_ip }}
                  username: ${{ secrets.EC2_USER }}
                  key: ${{ secrets.EC2_PRIVATE_KEY }}
                  script: |
                      cd /opt/app
                      npm ci --only=production
                      pm2 reload "node-server" --update-env || pm2 start /opt/app/bin/www --name "node-server" --update-env
                      sudo systemctl reload nginx

            - name: Disallow ssh on the security group of instance from the runner ip
              run: |
                  aws ec2 revoke-security-group-ingress \
                      --group-id ${{ steps.get_instance_security_group.outputs.security_group_id }} \
                      --protocol tcp \
                      --port 22 \
                      --cidr "${{ steps.get_runner_public_ip.outputs.runner_public_ip }}/32"
                      --region ${{ vars.AWS_DEFAULT_REGION }}
